{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "we chose the IMDB dataset it contains 50 000 movie reviews each one labeled as positive or negative"
      ],
      "metadata": {
        "id": "eCQOMT0h3OCM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0AkG9DrPDzh",
        "outputId": "9da71da5-bb14-4716-dacd-6dd6ae92e740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4040960397.py:7: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'imdb-dataset-of-50k-movie-reviews' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"IMDB Dataset.csv\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\",\n",
        "  file_path,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "since neural networks only work with numbers we converted each sentiment label into binary values ( negative->0 positive->1)"
      ],
      "metadata": {
        "id": "6G3FcUA73ax5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K0g5NOybPVL3"
      },
      "outputs": [],
      "source": [
        "df = df.copy()\n",
        "\n",
        "df[\"label\"] = df[\"sentiment\"].map({\n",
        "    \"negative\": 0,\n",
        "    \"positive\": 1\n",
        "}).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to clean our data we implemented a preprocessing function that converts text to lowercase, remove html tags and extra spaces then convert text into tokens"
      ],
      "metadata": {
        "id": "tWKgFXG83kBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf70J8OIPXWf",
        "outputId": "7cb01205-12af-448a-c2f7-d701c37c1721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download(\"punkt_tab\")\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we then applied this function on our reviews by adding a new column where each review is represented as a list of tokens"
      ],
      "metadata": {
        "id": "dAfSpvwH3uOy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3r14iVx6Padi"
      },
      "outputs": [],
      "source": [
        "df[\"tokens\"] = df[\"review\"].astype(str).apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we calculated the average and maximum length of our reviews , this helped us know the maximum sequence length for our models"
      ],
      "metadata": {
        "id": "2rj8V2hA32uy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzkJ1s4vPdp-",
        "outputId": "48c028aa-d603-43de-d9e2-aba2251ae5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length: 264.68574\n",
            "Max length: 2738\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = df[\"tokens\"].apply(len)\n",
        "print(\"Average length:\", np.mean(lengths))\n",
        "print(\"Max length:\", np.max(lengths))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we split our dataset into train,test and validation and we also used startification so we can keep the classes distribution balanced among sets"
      ],
      "metadata": {
        "id": "NqjNXa374Apd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXD2gwcFPgXW",
        "outputId": "b8c8b32d-e6f5-49b0-e925-ca6e078c9d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (32000, 4) Val: (8000, 4) Test: (10000, 4)\n",
            "Label balance (train):\n",
            " label\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "  sentiment  label                                             tokens\n",
            "0  positive      1  [one, of, the, other, reviewers, has, mentione...\n",
            "1  positive      1  [a, wonderful, little, production, ., the, fil...\n",
            "2  positive      1  [i, thought, this, was, a, wonderful, way, to,...\n",
            "3  negative      0  [basically, there, 's, a, family, where, a, li...\n",
            "4  positive      1  [petter, mattei, 's, ``, love, in, the, time, ...\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.2, random_state=42, stratify=train_df[\"label\"]\n",
        ")\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
        "print(\"Label balance (train):\\n\", train_df[\"label\"].value_counts(normalize=True))\n",
        "print(df[[\"sentiment\",\"label\",\"tokens\"]].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we then created our vocabulary of 20000 words (most frequent) and converted each word into its numerical index"
      ],
      "metadata": {
        "id": "puS0VCld4QTj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_14EHnh8PkRk",
        "outputId": "5677c3e4-34ec-4989-ab2c-8b5b66cf4f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 20000 | Example: ['<pad>', '<unk>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            "                                                  tokens  \\\n",
            "26680  [oh, yes, ,, i, have, to, agree, with, the, ot...   \n",
            "16648  [the, basic, hook, here, is, :, lincoln, is, s...   \n",
            "\n",
            "                                                     seq  label  \n",
            "26680  [440, 438, 3, 12, 34, 8, 1004, 18, 2, 405, 43,...      0  \n",
            "16648  [2, 1202, 3987, 140, 9, 88, 3633, 9, 630, 4, 1...      1  \n",
            "Example seq length: 536\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "MAX_VOCAB = 20000\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "PAD_IDX = 0\n",
        "UNK_IDX = 1\n",
        "\n",
        "counter = Counter()\n",
        "for tokens in train_df[\"tokens\"]:\n",
        "    counter.update(tokens)\n",
        "\n",
        "\n",
        "most_common = counter.most_common(MAX_VOCAB - 2)\n",
        "itos = [PAD_TOKEN, UNK_TOKEN] + [w for w, _ in most_common]   # index -> word\n",
        "stoi = {w: i for i, w in enumerate(itos)}                    # word -> index\n",
        "\n",
        "print(\"Vocab size:\", len(itos), \"| Example:\", itos[:10])\n",
        "def numericalize(tokens):\n",
        "    return [stoi.get(t, UNK_IDX) for t in tokens]\n",
        "\n",
        "train_df = train_df.copy()\n",
        "val_df   = val_df.copy()\n",
        "test_df  = test_df.copy()\n",
        "\n",
        "train_df[\"seq\"] = train_df[\"tokens\"].apply(numericalize)\n",
        "val_df[\"seq\"]   = val_df[\"tokens\"].apply(numericalize)\n",
        "test_df[\"seq\"]  = test_df[\"tokens\"].apply(numericalize)\n",
        "\n",
        "# sanity check\n",
        "print(train_df[[\"tokens\",\"seq\",\"label\"]].head(2))\n",
        "print(\"Example seq length:\", len(train_df[\"seq\"].iloc[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we truncated our sequence into 250 tokens since neural networks require a fixed sequence input length"
      ],
      "metadata": {
        "id": "ZJ_D9xqz4efE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwgIX8dCPqHo",
        "outputId": "ff79ed1c-1f58-417e-c7b4-955e49c37369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250 [440, 438, 3, 12, 34, 8, 1004, 18, 2, 405, 43, 1653, 13, 17, 3353]\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 250\n",
        "\n",
        "def pad_truncate(seq, max_len=MAX_LEN, pad_value=PAD_IDX):\n",
        "    if len(seq) > max_len:\n",
        "        return seq[:max_len]\n",
        "    return seq + [pad_value] * (max_len - len(seq))\n",
        "\n",
        "train_df[\"seq_pad\"] = train_df[\"seq\"].apply(pad_truncate)\n",
        "val_df[\"seq_pad\"]   = val_df[\"seq\"].apply(pad_truncate)\n",
        "test_df[\"seq_pad\"]  = test_df[\"seq\"].apply(pad_truncate)\n",
        "\n",
        "print(len(train_df[\"seq_pad\"].iloc[0]), train_df[\"seq_pad\"].iloc[0][:15])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to start training we used pytorch and created dataloaders to efficiently feed data into batches while training"
      ],
      "metadata": {
        "id": "Te3geQMJ4nFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_86ZqHKfPtOs",
        "outputId": "a13d6541-13a2-4b4a-cd11-11fbae4f7406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.X = df[\"seq_pad\"].tolist()\n",
        "        self.y = df[\"label\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.long)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(SeqDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(SeqDataset(val_df), batch_size=BATCH_SIZE)\n",
        "test_loader  = DataLoader(SeqDataset(test_df), batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZVt1CwM1P3ie"
      },
      "outputs": [],
      "source": [
        "X_train_text = train_df[\"review\"].astype(str).tolist()\n",
        "y_train = train_df[\"label\"].values\n",
        "\n",
        "X_val_text = val_df[\"review\"].astype(str).tolist()\n",
        "y_val = val_df[\"label\"].values\n",
        "\n",
        "X_test_text = test_df[\"review\"].astype(str).tolist()\n",
        "y_test = test_df[\"label\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53pn5lP-RjND",
        "outputId": "6aae3aa2-e9eb-49a8-f552-ffccf7d209b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vCzyXZacTOSh"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we created our word2vec embeddings and trained them on our training dataset"
      ],
      "metadata": {
        "id": "rxP7dDuA44eW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fGF_gnitTH1r"
      },
      "outputs": [],
      "source": [
        "EMBED_DIM = 100\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=train_df[\"tokens\"].tolist(),\n",
        "    vector_size=EMBED_DIM,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wD_NL9jkSgez"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(itos)\n",
        "\n",
        "embedding_matrix_w2v = np.random.normal(0, 0.05, (VOCAB_SIZE, EMBED_DIM)).astype(np.float32)\n",
        "embedding_matrix_w2v[PAD_IDX] = np.zeros(EMBED_DIM, dtype=np.float32)\n",
        "for word, idx in stoi.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix_w2v[idx] = w2v_model.wv[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OYZkX02KTgub"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "embedding_tensor_w2v = torch.tensor(embedding_matrix_w2v, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ne2powpbTi-W"
      },
      "outputs": [],
      "source": [
        "#GRU WITH WORD2VEC EMBEDDINGS\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRU_W2V(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_w2v,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=EMBED_DIM,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.gru(emb)\n",
        "        logits = self.fc(h[-1]).squeeze(1)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jfyxgzwsUoc-"
      },
      "outputs": [],
      "source": [
        "#RNN WITH WORD2VEC EMBEDDINGS\n",
        "class RNN_W2V(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_w2v,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=EMBED_DIM,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.rnn(emb)\n",
        "        logits = self.fc(h[-1]).squeeze(1)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rOAW7rXVUut4"
      },
      "outputs": [],
      "source": [
        "#BIDIRECTIONAL GRU WITH W2V EMBEDDINGS\n",
        "class BiGRU_W2V(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_w2v,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "\n",
        "        self.bigru = nn.GRU(\n",
        "            input_size=EMBED_DIM,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.bigru(emb)\n",
        "\n",
        "        # h shape: [2, B, H]\n",
        "        h_forward = h[0]\n",
        "        h_backward = h[1]\n",
        "\n",
        "        h_concat = torch.cat((h_forward, h_backward), dim=1)\n",
        "\n",
        "        logits = self.fc(h_concat).squeeze(1)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J4kySvbVUyPY"
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 128\n",
        "\n",
        "rnn_w2v_model = RNN_W2V(HIDDEN_DIM).to(device)\n",
        "gru_w2v_model = GRU_W2V(HIDDEN_DIM).to(device)\n",
        "bigru_w2v_model = BiGRU_W2V(HIDDEN_DIM).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "azkTJsLKVOcK"
      },
      "outputs": [],
      "source": [
        "!wget -q https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rozOHO27VdCY",
        "outputId": "205333c0-ecae-4ea3-a3f1-f2c3369fc6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded GloVe vectors: 400000\n"
          ]
        }
      ],
      "source": [
        "#created glove embeddings\n",
        "import numpy as np\n",
        "\n",
        "GLOVE_PATH = \"glove.6B.100d.txt\"\n",
        "EMBED_DIM = 100\n",
        "\n",
        "glove_index = {}\n",
        "with open(GLOVE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        parts = line.rstrip().split(\" \")\n",
        "        word = parts[0]\n",
        "        vec = np.array(parts[1:], dtype=np.float32)\n",
        "        glove_index[word] = vec\n",
        "\n",
        "print(\"Loaded GloVe vectors:\", len(glove_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSwnfjdNVfLu",
        "outputId": "81d7017d-5d2b-4a74-cee7-357113a74f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19729/20000 words in GloVe (98.65%)\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = len(itos)\n",
        "\n",
        "embedding_matrix_glove = np.random.normal(0, 0.05, (VOCAB_SIZE, EMBED_DIM)).astype(np.float32)\n",
        "embedding_matrix_glove[PAD_IDX] = np.zeros(EMBED_DIM, dtype=np.float32)\n",
        "found = 0\n",
        "for word, idx in stoi.items():\n",
        "    vec = glove_index.get(word)\n",
        "    if vec is not None:\n",
        "        embedding_matrix_glove[idx] = vec\n",
        "        found += 1\n",
        "\n",
        "print(f\"Found {found}/{VOCAB_SIZE} words in GloVe ({found/VOCAB_SIZE:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwh79yKKVhXi",
        "outputId": "b75cecfa-eedf-431f-da7e-0d5387bfa795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe embedding tensor shape: torch.Size([20000, 100])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "embedding_tensor_glove = torch.tensor(embedding_matrix_glove, dtype=torch.float32)\n",
        "print(\"GloVe embedding tensor shape:\", embedding_tensor_glove.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-gFMjqE0Vjd0"
      },
      "outputs": [],
      "source": [
        "#RNN WITH GLOVE EMBEDDINGS\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN_GloVe(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_glove,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "        self.rnn = nn.RNN(EMBED_DIM, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.rnn(emb)\n",
        "        return self.fc(h[-1]).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7An7KS2ZVlRP"
      },
      "outputs": [],
      "source": [
        "#GRU WITH GLOVE EMBEDDINGS\n",
        "class GRU_GloVe(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_glove,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "        self.gru = nn.GRU(EMBED_DIM, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.gru(emb)\n",
        "        return self.fc(h[-1]).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jO5eIEmaVnXk"
      },
      "outputs": [],
      "source": [
        "#BIDIRECTIONAL GRU WITH GLOVE EMBEDDINGS\n",
        "class BiGRU_GloVe(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_tensor_glove,\n",
        "            freeze=False,\n",
        "            padding_idx=PAD_IDX\n",
        "        )\n",
        "        self.bigru = nn.GRU(EMBED_DIM, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, h = self.bigru(emb)\n",
        "        h_cat = torch.cat((h[0], h[1]), dim=1)\n",
        "        return self.fc(h_cat).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wX9beD2AVqPp"
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 128\n",
        "\n",
        "rnn_glove = RNN_GloVe(HIDDEN_DIM).to(device)\n",
        "gru_glove = GRU_GloVe(HIDDEN_DIM).to(device)\n",
        "bigru_glove = BiGRU_GloVe(HIDDEN_DIM).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LpOOsOWw9y7w"
      },
      "outputs": [],
      "source": [
        "#CREATED TF IDF VECTORS\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(max_features=20000)\n",
        "tfidf_vec.fit(train_df[\"review\"].astype(str))\n",
        "\n",
        "tfidf_vocab = tfidf_vec.vocabulary_\n",
        "idf = tfidf_vec.idf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aPq5f7Zl91gT"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def token_tfidf_weights(tokens, max_len=MAX_LEN):\n",
        "    counts = Counter(tokens)\n",
        "    L = len(tokens)\n",
        "\n",
        "    weights = []\n",
        "    for t in tokens[:max_len]:\n",
        "        j = tfidf_vocab.get(t, None)\n",
        "        if j is None:\n",
        "            weights.append(0.0)\n",
        "        else:\n",
        "            tf = counts[t] / L\n",
        "            weights.append(tf * float(idf[j]))\n",
        "\n",
        "    if len(weights) < max_len:\n",
        "        weights += [0.0] * (max_len - len(weights))\n",
        "    return weights\n",
        "train_df = train_df.copy()\n",
        "val_df   = val_df.copy()\n",
        "test_df  = test_df.copy()\n",
        "\n",
        "train_df[\"tfidf_w\"] = train_df[\"tokens\"].apply(token_tfidf_weights)\n",
        "val_df[\"tfidf_w\"]   = val_df[\"tokens\"].apply(token_tfidf_weights)\n",
        "test_df[\"tfidf_w\"]  = test_df[\"tokens\"].apply(token_tfidf_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VZCHGnvo93Kw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SeqTfidfDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.X = df[\"seq_pad\"].tolist()\n",
        "        self.W = df[\"tfidf_w\"].tolist()\n",
        "        self.y = df[\"label\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.long)\n",
        "        w = torch.tensor(self.W[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "        return x, w, y\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "train_loader_tfidfseq = DataLoader(SeqTfidfDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_tfidfseq   = DataLoader(SeqTfidfDataset(val_df), batch_size=BATCH_SIZE)\n",
        "test_loader_tfidfseq  = DataLoader(SeqTfidfDataset(test_df), batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qE5OaCgn9_oC"
      },
      "outputs": [],
      "source": [
        "#RNN WITH TF IDF SEQ\n",
        "\n",
        "class RNN_TFIDFSeq(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        emb = self.embedding(x)\n",
        "        emb = emb * w.unsqueeze(-1)\n",
        "        _, h = self.rnn(emb)\n",
        "        return self.fc(h[-1]).squeeze(1)\n",
        "\n",
        "#GRU WITH TF IDF SEQ\n",
        "class GRU_TFIDFSeq(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        emb = self.embedding(x)\n",
        "        emb = emb * w.unsqueeze(-1)\n",
        "        _, h = self.gru(emb)\n",
        "        return self.fc(h[-1]).squeeze(1)\n",
        "\n",
        "#BIGRU WITH TF IDF SEQ\n",
        "class BiGRU_TFIDFSeq(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, pad_idx, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.bigru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        emb = self.embedding(x)\n",
        "        emb = emb * w.unsqueeze(-1)\n",
        "        _, h = self.bigru(emb)\n",
        "        h = self.dropout(h)\n",
        "        h_cat = torch.cat((h[0], h[1]), dim=1)\n",
        "        return self.fc(h_cat).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6P1fkhQv-FBf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch\n",
        "\n",
        "def run_epoch_tfidfseq(model, loader, criterion, optimizer=None, device=\"cuda\", grad_clip=1.0):\n",
        "    train = optimizer is not None\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x, w, y in loader:\n",
        "        x = x.to(device)\n",
        "        w = w.to(device)\n",
        "        y = y.to(device).float()          # IMPORTANT\n",
        "\n",
        "        logits = model(x, w).view(-1)     # [B]\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            if grad_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "\n",
        "        preds = (torch.sigmoid(logits) >= 0.5).long().detach().cpu().numpy()\n",
        "        labels = y.long().detach().cpu().numpy()\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1  = f1_score(all_labels, all_preds)\n",
        "    return avg_loss, acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GKYJzGWFNw7o"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "def fit_model_tfidfseq(model, train_loader, val_loader, device,\n",
        "                       epochs=6, lr=1e-3, weight_decay=0.0,\n",
        "                       patience=2, grad_clip=1.0):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    best_state = None\n",
        "    best_f1 = -1.0\n",
        "    bad_epochs = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        tr_loss, tr_acc, tr_f1 = run_epoch_tfidfseq(\n",
        "            model, train_loader, criterion, optimizer=optimizer, device=device, grad_clip=grad_clip\n",
        "        )\n",
        "        va_loss, va_acc, va_f1 = run_epoch_tfidfseq(\n",
        "            model, val_loader, criterion, optimizer=None, device=device\n",
        "        )\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": tr_loss, \"train_acc\": tr_acc, \"train_f1\": tr_f1,\n",
        "            \"val_loss\": va_loss, \"val_acc\": va_acc, \"val_f1\": va_f1,\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} | \"\n",
        "              f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} f1 {tr_f1:.4f} | \"\n",
        "              f\"val loss {va_loss:.4f} acc {va_acc:.4f} f1 {va_f1:.4f}\")\n",
        "\n",
        "        if va_f1 > best_f1:\n",
        "            best_f1 = va_f1\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= patience:\n",
        "                print(f\"Early stopping (no val F1 improvement for {patience} epochs).\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model_tfidfseq(model, test_loader, device):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    te_loss, te_acc, te_f1 = run_epoch_tfidfseq(model, test_loader, criterion, optimizer=None, device=device)\n",
        "    print(f\"TEST | loss {te_loss:.4f} acc {te_acc:.4f} f1 {te_f1:.4f}\")\n",
        "    return {\"loss\": te_loss, \"acc\": te_acc, \"f1\": te_f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the run grid function is to experiment models with different hyperparameters"
      ],
      "metadata": {
        "id": "U1nQ0W5f6Uyb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BuMyipNaNz53"
      },
      "outputs": [],
      "source": [
        "def run_grid_tfidfseq(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "\n",
        "        model, _ = fit_model_tfidfseq(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "        )\n",
        "\n",
        "        test_m = test_model_tfidfseq(model, test_loader, device)\n",
        "\n",
        "        results.append({**cfg,\n",
        "                        \"test_loss\": test_m[\"loss\"],\n",
        "                        \"test_acc\": test_m[\"acc\"],\n",
        "                        \"test_f1\": test_m[\"f1\"]})\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hFlfucDohGgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, df, x_col=\"seq_pad\", y_col=\"label\"):\n",
        "        self.X = df[x_col].tolist()\n",
        "        self.y = df[y_col].astype(int).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.long)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(train_df, val_df, test_df, batch_size=64, num_workers=0):\n",
        "    train_loader = DataLoader(\n",
        "        SeqDataset(train_df), batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        SeqDataset(val_df), batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        SeqDataset(test_df), batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=True\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "#Metrics\n",
        "@torch.no_grad()\n",
        "def logits_to_metrics(logits: torch.Tensor, y: torch.Tensor, threshold=0.5):\n",
        "    \"\"\"\n",
        "    logits: [N] (raw outputs before sigmoid)\n",
        "    y     : [N] (0/1 floats)\n",
        "    \"\"\"\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs >= threshold).long()\n",
        "    y_int = y.long()\n",
        "\n",
        "    acc = (preds == y_int).float().mean().item()\n",
        "\n",
        "    # confusion matrix counts: TP, FP, TN, FN\n",
        "    tp = ((preds == 1) & (y_int == 1)).sum().item()\n",
        "    fp = ((preds == 1) & (y_int == 0)).sum().item()\n",
        "    tn = ((preds == 0) & (y_int == 0)).sum().item()\n",
        "    fn = ((preds == 0) & (y_int == 1)).sum().item()\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-12)\n",
        "    recall    = tp / (tp + fn + 1e-12)\n",
        "    f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
        "\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"cm\": np.array([[tn, fp],[fn, tp]], dtype=int)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device, grad_clip=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        logits = logits.view(-1)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        if grad_clip is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_logits = []\n",
        "    all_y = []\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        logits = model(xb).view(-1)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_y.append(yb.detach().cpu())\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    all_y = torch.cat(all_y, dim=0)\n",
        "\n",
        "    metrics = logits_to_metrics(all_logits, all_y)\n",
        "    metrics[\"loss\"] = total_loss / len(loader.dataset)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Full fit loop (with early stopping on val F1)\n",
        "def fit_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    epochs=6,\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    patience=2,\n",
        "    grad_clip=1.0,\n",
        "    pos_weight=None,  # set if dataset is imbalanced\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    if pos_weight is not None:\n",
        "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n",
        "    else:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    history = []\n",
        "    best_state = None\n",
        "    best_f1 = -1.0\n",
        "    bad_epochs = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, grad_clip=grad_clip)\n",
        "        val_metrics = eval_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        row = {\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_metrics[\"loss\"],\n",
        "            \"val_acc\": val_metrics[\"acc\"],\n",
        "            \"val_precision\": val_metrics[\"precision\"],\n",
        "            \"val_recall\": val_metrics[\"recall\"],\n",
        "            \"val_f1\": val_metrics[\"f1\"],\n",
        "        }\n",
        "        history.append(row)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{epochs} | \"\n",
        "            f\"train loss {train_loss:.4f} | \"\n",
        "            f\"val loss {val_metrics['loss']:.4f} | \"\n",
        "            f\"val acc {val_metrics['acc']:.4f} | \"\n",
        "            f\"val f1 {val_metrics['f1']:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_metrics[\"f1\"] > best_f1:\n",
        "            best_f1 = val_metrics[\"f1\"]\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= patience:\n",
        "                print(f\"Early stopping (no val F1 improvement for {patience} epochs).\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(model, test_loader, device):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    metrics = eval_one_epoch(model.to(device), test_loader, criterion, device)\n",
        "    print(\"\\nTEST:\")\n",
        "    print(f\"loss={metrics['loss']:.4f} acc={metrics['acc']:.4f} \"\n",
        "          f\"prec={metrics['precision']:.4f} rec={metrics['recall']:.4f} f1={metrics['f1']:.4f}\")\n",
        "    print(\"Confusion matrix [[TN, FP],[FN, TP]]:\\n\", metrics[\"cm\"])\n",
        "    return metrics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TRAINING**:"
      ],
      "metadata": {
        "id": "uNbTeOgg61T-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruhI0X57jRhL",
        "outputId": "3d38a53d-fe78-4d5c-a88c-f92409621ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.6622 | val loss 0.6456 | val acc 0.6201 | val f1 0.4991\n",
            "Epoch 2/6 | train loss 0.4288 | val loss 0.3245 | val acc 0.8594 | val f1 0.8471\n",
            "Epoch 3/6 | train loss 0.2490 | val loss 0.2508 | val acc 0.8971 | val f1 0.8969\n",
            "Epoch 4/6 | train loss 0.1600 | val loss 0.2630 | val acc 0.9011 | val f1 0.9026\n",
            "Epoch 5/6 | train loss 0.0955 | val loss 0.3348 | val acc 0.8895 | val f1 0.8855\n",
            "Epoch 6/6 | train loss 0.0535 | val loss 0.4382 | val acc 0.8925 | val f1 0.8904\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2577 acc=0.9011 prec=0.8895 rec=0.9160 f1=0.9026\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4431  569]\n",
            " [ 420 4580]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6180 | val loss 0.5026 | val acc 0.7909 | val f1 0.7892\n",
            "Epoch 2/6 | train loss 0.4153 | val loss 0.2905 | val acc 0.8790 | val f1 0.8810\n",
            "Epoch 3/6 | train loss 0.2425 | val loss 0.2513 | val acc 0.8935 | val f1 0.8927\n",
            "Epoch 4/6 | train loss 0.1571 | val loss 0.2571 | val acc 0.8975 | val f1 0.8978\n",
            "Epoch 5/6 | train loss 0.0936 | val loss 0.3389 | val acc 0.8959 | val f1 0.8974\n",
            "Epoch 6/6 | train loss 0.0528 | val loss 0.3625 | val acc 0.8854 | val f1 0.8902\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2501 acc=0.8999 prec=0.9019 rec=0.8974 f1=0.8996\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4512  488]\n",
            " [ 513 4487]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6721 | val loss 0.6414 | val acc 0.6083 | val f1 0.7012\n",
            "Epoch 2/6 | train loss 0.4253 | val loss 0.2925 | val acc 0.8735 | val f1 0.8680\n",
            "Epoch 3/6 | train loss 0.2433 | val loss 0.2451 | val acc 0.9016 | val f1 0.9016\n",
            "Epoch 4/6 | train loss 0.1568 | val loss 0.2522 | val acc 0.9000 | val f1 0.8988\n",
            "Epoch 5/6 | train loss 0.0877 | val loss 0.3103 | val acc 0.8974 | val f1 0.8968\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2459 acc=0.8974 prec=0.9004 rec=0.8936 f1=0.8970\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4506  494]\n",
            " [ 532 4468]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6463 | val loss 0.5963 | val acc 0.7355 | val f1 0.7639\n",
            "Epoch 2/6 | train loss 0.5480 | val loss 0.4921 | val acc 0.7934 | val f1 0.7731\n",
            "Epoch 3/6 | train loss 0.4437 | val loss 0.3772 | val acc 0.8568 | val f1 0.8600\n",
            "Epoch 4/6 | train loss 0.3073 | val loss 0.2761 | val acc 0.8854 | val f1 0.8848\n",
            "Epoch 5/6 | train loss 0.2273 | val loss 0.2650 | val acc 0.8954 | val f1 0.8981\n",
            "Epoch 6/6 | train loss 0.1702 | val loss 0.2844 | val acc 0.8942 | val f1 0.8933\n",
            "\n",
            "TEST:\n",
            "loss=0.2668 acc=0.8925 prec=0.8769 rec=0.9132 f1=0.8947\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4359  641]\n",
            " [ 434 4566]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.6556 | val loss 0.5696 | val acc 0.7467 | val f1 0.7812\n",
            "Epoch 2/6 | train loss 0.4277 | val loss 0.2993 | val acc 0.8729 | val f1 0.8692\n",
            "Epoch 3/6 | train loss 0.2500 | val loss 0.2565 | val acc 0.8915 | val f1 0.8888\n",
            "Epoch 4/6 | train loss 0.1620 | val loss 0.2767 | val acc 0.8951 | val f1 0.8978\n",
            "Epoch 5/6 | train loss 0.1024 | val loss 0.3121 | val acc 0.8929 | val f1 0.8943\n",
            "Epoch 6/6 | train loss 0.0628 | val loss 0.3635 | val acc 0.8846 | val f1 0.8813\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2665 acc=0.8989 prec=0.8797 rec=0.9242 f1=0.9014\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4368  632]\n",
            " [ 379 4621]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#GRU with word2vec embeddings\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = GRU_W2V(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: GRU_W2V(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "6aaqKai4mLPc",
        "outputId": "4421218f-2a4b-4041-f86e-ecefbdcd6c6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.250119    0.8999        0.901910   \n",
              "1         256  0.0010       6   0.245872    0.8974        0.900443   \n",
              "2         128  0.0005       6   0.266774    0.8925        0.876896   \n",
              "3         128  0.0010       6   0.266466    0.8989        0.879688   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.8974  0.899649           NaN  \n",
              "1       0.8936  0.897009           NaN  \n",
              "2       0.9132  0.894680           NaN  \n",
              "3       0.9242  0.901395       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-303d45fc-6980-4de1-b292-4ce8a02f9ec3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.250119</td>\n",
              "      <td>0.8999</td>\n",
              "      <td>0.901910</td>\n",
              "      <td>0.8974</td>\n",
              "      <td>0.899649</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.245872</td>\n",
              "      <td>0.8974</td>\n",
              "      <td>0.900443</td>\n",
              "      <td>0.8936</td>\n",
              "      <td>0.897009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.266774</td>\n",
              "      <td>0.8925</td>\n",
              "      <td>0.876896</td>\n",
              "      <td>0.9132</td>\n",
              "      <td>0.894680</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.266466</td>\n",
              "      <td>0.8989</td>\n",
              "      <td>0.879688</td>\n",
              "      <td>0.9242</td>\n",
              "      <td>0.901395</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-303d45fc-6980-4de1-b292-4ce8a02f9ec3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-303d45fc-6980-4de1-b292-4ce8a02f9ec3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-303d45fc-6980-4de1-b292-4ce8a02f9ec3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010892419447554074,\n        \"min\": 0.24587220578193664,\n        \"max\": 0.2667743599653244,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.24587220578193664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00328164974415055,\n        \"min\": 0.8924999833106995,\n        \"max\": 0.8999000191688538,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8974000215530396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013274819823313399,\n        \"min\": 0.8768964855002879,\n        \"max\": 0.9019095477386933,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9004433696090285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014212201330781445,\n        \"min\": 0.8935999999999998,\n        \"max\": 0.9241999999999998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8935999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0029503625403863296,\n        \"min\": 0.8946801214847552,\n        \"max\": 0.9013947137418195,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8970086328041575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8BM__rDnlCY",
        "outputId": "deba0396-35b5-4602-c551-81b601782108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.6280 | val loss 0.4138 | val acc 0.8411 | val f1 0.8469\n",
            "Epoch 2/6 | train loss 0.3107 | val loss 0.2622 | val acc 0.8940 | val f1 0.8978\n",
            "Epoch 3/6 | train loss 0.1828 | val loss 0.2536 | val acc 0.8950 | val f1 0.8948\n",
            "Epoch 4/6 | train loss 0.1123 | val loss 0.3002 | val acc 0.8880 | val f1 0.8926\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2700 acc=0.8898 prec=0.8680 rec=0.9194 f1=0.8930\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4301  699]\n",
            " [ 403 4597]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6389 | val loss 0.4918 | val acc 0.7939 | val f1 0.8142\n",
            "Epoch 2/6 | train loss 0.3436 | val loss 0.2730 | val acc 0.8870 | val f1 0.8857\n",
            "Epoch 3/6 | train loss 0.2000 | val loss 0.2741 | val acc 0.8855 | val f1 0.8915\n",
            "Epoch 4/6 | train loss 0.1258 | val loss 0.2813 | val acc 0.8882 | val f1 0.8868\n",
            "Epoch 5/6 | train loss 0.0732 | val loss 0.3487 | val acc 0.8856 | val f1 0.8853\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2753 acc=0.8894 prec=0.8530 rec=0.9410 f1=0.8948\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4189  811]\n",
            " [ 295 4705]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.5765 | val loss 0.2882 | val acc 0.8780 | val f1 0.8805\n",
            "Epoch 2/6 | train loss 0.2465 | val loss 0.2621 | val acc 0.8882 | val f1 0.8829\n",
            "Epoch 3/6 | train loss 0.1583 | val loss 0.2517 | val acc 0.9010 | val f1 0.9010\n",
            "Epoch 4/6 | train loss 0.0885 | val loss 0.3211 | val acc 0.8926 | val f1 0.8930\n",
            "Epoch 5/6 | train loss 0.0438 | val loss 0.4407 | val acc 0.8805 | val f1 0.8763\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2591 acc=0.8990 prec=0.9027 rec=0.8944 f1=0.8985\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4518  482]\n",
            " [ 528 4472]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6772 | val loss 0.5931 | val acc 0.7039 | val f1 0.6313\n",
            "Epoch 2/6 | train loss 0.4451 | val loss 0.3353 | val acc 0.8652 | val f1 0.8632\n",
            "Epoch 3/6 | train loss 0.2709 | val loss 0.2674 | val acc 0.8894 | val f1 0.8922\n",
            "Epoch 4/6 | train loss 0.1959 | val loss 0.2627 | val acc 0.8941 | val f1 0.8936\n",
            "Epoch 5/6 | train loss 0.1451 | val loss 0.2768 | val acc 0.8949 | val f1 0.8955\n",
            "Epoch 6/6 | train loss 0.1026 | val loss 0.3192 | val acc 0.8844 | val f1 0.8804\n",
            "\n",
            "TEST:\n",
            "loss=0.2774 acc=0.8925 prec=0.8940 rec=0.8906 f1=0.8923\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4472  528]\n",
            " [ 547 4453]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.5900 | val loss 0.4260 | val acc 0.8290 | val f1 0.8417\n",
            "Epoch 2/6 | train loss 0.3122 | val loss 0.2753 | val acc 0.8841 | val f1 0.8893\n",
            "Epoch 3/6 | train loss 0.1811 | val loss 0.2740 | val acc 0.8875 | val f1 0.8910\n",
            "Epoch 4/6 | train loss 0.1018 | val loss 0.3189 | val acc 0.8857 | val f1 0.8834\n",
            "Epoch 5/6 | train loss 0.0577 | val loss 0.3963 | val acc 0.8814 | val f1 0.8833\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2709 acc=0.8910 prec=0.8715 rec=0.9172 f1=0.8938\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4324  676]\n",
            " [ 414 4586]]\n"
          ]
        }
      ],
      "source": [
        "#GRU with glove\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = GRU_GloVe(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: GRU_GloVe(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "hRTk83BgzpSJ",
        "outputId": "cb822a00-b574-45ee-98ea-b96af143d960"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.275270    0.8894        0.852973   \n",
              "1         256  0.0010       6   0.259081    0.8990        0.902705   \n",
              "2         128  0.0005       6   0.277446    0.8925        0.893997   \n",
              "3         128  0.0010       6   0.270923    0.8910        0.871532   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.9410  0.894827           NaN  \n",
              "1       0.8944  0.898533           NaN  \n",
              "2       0.8906  0.892295           NaN  \n",
              "3       0.9172  0.893783       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88b36049-fe5f-404d-b4c3-9bf1b1a3be8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.275270</td>\n",
              "      <td>0.8894</td>\n",
              "      <td>0.852973</td>\n",
              "      <td>0.9410</td>\n",
              "      <td>0.894827</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.259081</td>\n",
              "      <td>0.8990</td>\n",
              "      <td>0.902705</td>\n",
              "      <td>0.8944</td>\n",
              "      <td>0.898533</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.8925</td>\n",
              "      <td>0.893997</td>\n",
              "      <td>0.8906</td>\n",
              "      <td>0.892295</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.270923</td>\n",
              "      <td>0.8910</td>\n",
              "      <td>0.871532</td>\n",
              "      <td>0.9172</td>\n",
              "      <td>0.893783</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88b36049-fe5f-404d-b4c3-9bf1b1a3be8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88b36049-fe5f-404d-b4c3-9bf1b1a3be8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88b36049-fe5f-404d-b4c3-9bf1b1a3be8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00819440441069708,\n        \"min\": 0.25908122148513796,\n        \"max\": 0.27744625971317294,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.25908122148513796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004211391411981606,\n        \"min\": 0.8894000053405762,\n        \"max\": 0.8989999890327454,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8989999890327454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02245907376529913,\n        \"min\": 0.8529731689630166,\n        \"max\": 0.9027048849414613,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9027048849414613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023309511649396108,\n        \"min\": 0.8905999999999998,\n        \"max\": 0.9409999999999998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8943999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0026602895909646216,\n        \"min\": 0.8922953611857537,\n        \"max\": 0.8985332529631326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8985332529631326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpDGuc1KoUtA",
        "outputId": "58bf3da5-fe70-409c-f280-95f013e408ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.6940 | val loss 0.7010 | val acc 0.4990 | val f1 0.5613\n",
            "Epoch 2/6 | train loss 0.6896 | val loss 0.6845 | val acc 0.5470 | val f1 0.6565\n",
            "Epoch 3/6 | train loss 0.6910 | val loss 0.6877 | val acc 0.5359 | val f1 0.6318\n",
            "Epoch 4/6 | train loss 0.6784 | val loss 0.6504 | val acc 0.6480 | val f1 0.6393\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6877 acc=0.5368 prec=0.5225 rec=0.8562 f1=0.6489\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[1087 3913]\n",
            " [ 719 4281]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6916 | val loss 0.6866 | val acc 0.5246 | val f1 0.3424\n",
            "Epoch 2/6 | train loss 0.6822 | val loss 0.6805 | val acc 0.5476 | val f1 0.3776\n",
            "Epoch 3/6 | train loss 0.6747 | val loss 0.6793 | val acc 0.5431 | val f1 0.5333\n",
            "Epoch 4/6 | train loss 0.6574 | val loss 0.6772 | val acc 0.6087 | val f1 0.4720\n",
            "Epoch 5/6 | train loss 0.6132 | val loss 0.6452 | val acc 0.6647 | val f1 0.6843\n",
            "Epoch 6/6 | train loss 0.5819 | val loss 0.6330 | val acc 0.6733 | val f1 0.6633\n",
            "\n",
            "TEST:\n",
            "loss=0.6491 acc=0.6614 prec=0.6441 rec=0.7214 f1=0.6806\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[3007 1993]\n",
            " [1393 3607]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6975 | val loss 0.7002 | val acc 0.4856 | val f1 0.3715\n",
            "Epoch 2/6 | train loss 0.6939 | val loss 0.6907 | val acc 0.5191 | val f1 0.4226\n",
            "Epoch 3/6 | train loss 0.6928 | val loss 0.6912 | val acc 0.5161 | val f1 0.5696\n",
            "Epoch 4/6 | train loss 0.6937 | val loss 0.6976 | val acc 0.5255 | val f1 0.4914\n",
            "Epoch 5/6 | train loss 0.6934 | val loss 0.6926 | val acc 0.5242 | val f1 0.5572\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6904 acc=0.5123 prec=0.5099 rec=0.6356 f1=0.5658\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[1945 3055]\n",
            " [1822 3178]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6912 | val loss 0.6862 | val acc 0.5362 | val f1 0.6488\n",
            "Epoch 2/6 | train loss 0.6685 | val loss 0.6047 | val acc 0.7081 | val f1 0.7311\n",
            "Epoch 3/6 | train loss 0.6387 | val loss 0.6488 | val acc 0.6410 | val f1 0.6000\n",
            "Epoch 4/6 | train loss 0.6165 | val loss 0.5910 | val acc 0.7200 | val f1 0.7196\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6089 acc=0.7055 prec=0.6761 rec=0.7890 f1=0.7282\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[3110 1890]\n",
            " [1055 3945]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.6904 | val loss 0.6818 | val acc 0.5879 | val f1 0.4322\n",
            "Epoch 2/6 | train loss 0.6799 | val loss 0.6634 | val acc 0.6165 | val f1 0.6222\n",
            "Epoch 3/6 | train loss 0.6834 | val loss 0.6937 | val acc 0.5157 | val f1 0.3526\n",
            "Epoch 4/6 | train loss 0.6893 | val loss 0.6862 | val acc 0.5434 | val f1 0.4743\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6638 acc=0.6186 prec=0.6162 rec=0.6290 f1=0.6225\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[3041 1959]\n",
            " [1855 3145]]\n"
          ]
        }
      ],
      "source": [
        "#RNN WITH W2V\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = RNN_W2V(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: RNN_W2V(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "frD8BKd10Dzd",
        "outputId": "5c55ed1b-c1db-45bf-a87d-d8c6c2527a1a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.649062    0.6614        0.644107   \n",
              "1         256  0.0010       6   0.690358    0.5123        0.509867   \n",
              "2         128  0.0005       6   0.608887    0.7055        0.676093   \n",
              "3         128  0.0010       6   0.663791    0.6186        0.616183   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.7214  0.680566           NaN  \n",
              "1       0.6356  0.565833           NaN  \n",
              "2       0.7890  0.728196           NaN  \n",
              "3       0.6290  0.622526       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fd26098-72db-4407-9f70-be2aecd540d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.649062</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>0.644107</td>\n",
              "      <td>0.7214</td>\n",
              "      <td>0.680566</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.690358</td>\n",
              "      <td>0.5123</td>\n",
              "      <td>0.509867</td>\n",
              "      <td>0.6356</td>\n",
              "      <td>0.565833</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>0.7055</td>\n",
              "      <td>0.676093</td>\n",
              "      <td>0.7890</td>\n",
              "      <td>0.728196</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.663791</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.616183</td>\n",
              "      <td>0.6290</td>\n",
              "      <td>0.622526</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fd26098-72db-4407-9f70-be2aecd540d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fd26098-72db-4407-9f70-be2aecd540d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fd26098-72db-4407-9f70-be2aecd540d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034027057595776365,\n        \"min\": 0.6088872469902039,\n        \"max\": 0.6903581728935242,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6903581728935242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0827571732853997,\n        \"min\": 0.5123000144958496,\n        \"max\": 0.7055000066757202,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5123000144958496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07208014238522058,\n        \"min\": 0.5098668377988127,\n        \"max\": 0.6760925449871464,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5098668377988127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07618195324353397,\n        \"min\": 0.6289999999999999,\n        \"max\": 0.7889999999999998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6355999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07044080630946548,\n        \"min\": 0.5658328140295958,\n        \"max\": 0.7281956622053173,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5658328140295958\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZLK7O4po3Qh",
        "outputId": "0abb004c-f1ad-4bb7-9ea5-ea207f17863d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.6936 | val loss 0.6948 | val acc 0.5115 | val f1 0.0995\n",
            "Epoch 2/6 | train loss 0.6929 | val loss 0.6927 | val acc 0.5067 | val f1 0.3516\n",
            "Epoch 3/6 | train loss 0.6882 | val loss 0.6939 | val acc 0.5139 | val f1 0.6447\n",
            "Epoch 4/6 | train loss 0.6718 | val loss 0.7037 | val acc 0.5090 | val f1 0.1717\n",
            "Epoch 5/6 | train loss 0.6411 | val loss 0.7027 | val acc 0.5268 | val f1 0.5467\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6919 acc=0.5131 prec=0.5075 rec=0.8820 f1=0.6443\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[ 721 4279]\n",
            " [ 590 4410]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6914 | val loss 0.6955 | val acc 0.5045 | val f1 0.6668\n",
            "Epoch 2/6 | train loss 0.6905 | val loss 0.6911 | val acc 0.5335 | val f1 0.6057\n",
            "Epoch 3/6 | train loss 0.6886 | val loss 0.6986 | val acc 0.5312 | val f1 0.5447\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6955 acc=0.5040 prec=0.5020 rec=0.9922 f1=0.6667\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[  79 4921]\n",
            " [  39 4961]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6939 | val loss 0.6928 | val acc 0.5181 | val f1 0.6309\n",
            "Epoch 2/6 | train loss 0.6986 | val loss 0.6926 | val acc 0.5132 | val f1 0.1771\n",
            "Epoch 3/6 | train loss 0.6935 | val loss 0.6918 | val acc 0.5157 | val f1 0.6458\n",
            "Epoch 4/6 | train loss 0.6824 | val loss 0.6564 | val acc 0.6291 | val f1 0.5682\n",
            "Epoch 5/6 | train loss 0.6363 | val loss 0.6415 | val acc 0.6585 | val f1 0.5627\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6918 acc=0.5157 prec=0.5091 rec=0.8782 f1=0.6446\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[ 766 4234]\n",
            " [ 609 4391]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.6923 | val loss 0.6904 | val acc 0.5244 | val f1 0.5999\n",
            "Epoch 2/6 | train loss 0.6675 | val loss 0.6861 | val acc 0.5689 | val f1 0.4758\n",
            "Epoch 3/6 | train loss 0.6418 | val loss 0.6303 | val acc 0.6736 | val f1 0.6514\n",
            "Epoch 4/6 | train loss 0.6140 | val loss 0.6436 | val acc 0.6661 | val f1 0.5890\n",
            "Epoch 5/6 | train loss 0.5706 | val loss 0.6302 | val acc 0.6899 | val f1 0.7105\n",
            "Epoch 6/6 | train loss 0.5384 | val loss 0.6668 | val acc 0.6715 | val f1 0.6639\n",
            "\n",
            "TEST:\n",
            "loss=0.6239 acc=0.6978 prec=0.6707 rec=0.7772 f1=0.7200\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[3092 1908]\n",
            " [1114 3886]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.6929 | val loss 0.6926 | val acc 0.5071 | val f1 0.1396\n",
            "Epoch 2/6 | train loss 0.6876 | val loss 0.6929 | val acc 0.5157 | val f1 0.6043\n",
            "Epoch 3/6 | train loss 0.6816 | val loss 0.7125 | val acc 0.5070 | val f1 0.1911\n",
            "Epoch 4/6 | train loss 0.6794 | val loss 0.6982 | val acc 0.5140 | val f1 0.2781\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.6927 acc=0.5089 prec=0.5061 rec=0.7366 f1=0.6000\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[1406 3594]\n",
            " [1317 3683]]\n"
          ]
        }
      ],
      "source": [
        "#RNN WITH GLOVE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = RNN_GloVe(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: RNN_GloVe(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "5KNm9aUQ0SgS",
        "outputId": "209e7147-ca75-454b-d181-7b356b1f4dad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.695475    0.5040        0.502024   \n",
              "1         256  0.0010       6   0.691791    0.5157        0.509101   \n",
              "2         128  0.0005       6   0.623915    0.6978        0.670694   \n",
              "3         128  0.0010       6   0.692689    0.5089        0.506115   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.9922  0.666711           NaN  \n",
              "1       0.8782  0.644550           NaN  \n",
              "2       0.7772  0.720030           NaN  \n",
              "3       0.7366  0.599984       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-425a687f-5dac-4151-bfe2-99e1adafb803\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.695475</td>\n",
              "      <td>0.5040</td>\n",
              "      <td>0.502024</td>\n",
              "      <td>0.9922</td>\n",
              "      <td>0.666711</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.691791</td>\n",
              "      <td>0.5157</td>\n",
              "      <td>0.509101</td>\n",
              "      <td>0.8782</td>\n",
              "      <td>0.644550</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.623915</td>\n",
              "      <td>0.6978</td>\n",
              "      <td>0.670694</td>\n",
              "      <td>0.7772</td>\n",
              "      <td>0.720030</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.692689</td>\n",
              "      <td>0.5089</td>\n",
              "      <td>0.506115</td>\n",
              "      <td>0.7366</td>\n",
              "      <td>0.599984</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-425a687f-5dac-4151-bfe2-99e1adafb803')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-425a687f-5dac-4151-bfe2-99e1adafb803 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-425a687f-5dac-4151-bfe2-99e1adafb803');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03473721030549921,\n        \"min\": 0.6239147737503051,\n        \"max\": 0.695474619102478,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.691791092300415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09425549738962818,\n        \"min\": 0.5040000081062317,\n        \"max\": 0.6977999806404114,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5156999826431274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08252450552545214,\n        \"min\": 0.5020238818053024,\n        \"max\": 0.6706938211943388,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5091014492753622\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11418270446963497,\n        \"min\": 0.7365999999999999,\n        \"max\": 0.9921999999999999,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8781999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04990061931747388,\n        \"min\": 0.5999837093747716,\n        \"max\": 0.7200296460991874,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6445504587151314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWIEi9Ilp1wK",
        "outputId": "28af640a-1abf-42f1-cad3-633d0086be94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.4669 | val loss 0.3020 | val acc 0.8740 | val f1 0.8757\n",
            "Epoch 2/6 | train loss 0.2758 | val loss 0.2541 | val acc 0.8955 | val f1 0.8938\n",
            "Epoch 3/6 | train loss 0.1819 | val loss 0.2670 | val acc 0.8917 | val f1 0.8876\n",
            "Epoch 4/6 | train loss 0.1084 | val loss 0.3353 | val acc 0.8820 | val f1 0.8894\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2637 acc=0.8920 prec=0.9087 rec=0.8716 f1=0.8898\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4562  438]\n",
            " [ 642 4358]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.4897 | val loss 0.3218 | val acc 0.8646 | val f1 0.8594\n",
            "Epoch 2/6 | train loss 0.2725 | val loss 0.2588 | val acc 0.8955 | val f1 0.8998\n",
            "Epoch 3/6 | train loss 0.1832 | val loss 0.2690 | val acc 0.8972 | val f1 0.9006\n",
            "Epoch 4/6 | train loss 0.1081 | val loss 0.2733 | val acc 0.8989 | val f1 0.9001\n",
            "Epoch 5/6 | train loss 0.0581 | val loss 0.3802 | val acc 0.8920 | val f1 0.8920\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2700 acc=0.8949 prec=0.8726 rec=0.9248 f1=0.8980\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4325  675]\n",
            " [ 376 4624]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.4659 | val loss 0.3001 | val acc 0.8746 | val f1 0.8769\n",
            "Epoch 2/6 | train loss 0.2552 | val loss 0.2499 | val acc 0.9014 | val f1 0.9010\n",
            "Epoch 3/6 | train loss 0.1652 | val loss 0.2500 | val acc 0.8967 | val f1 0.8945\n",
            "Epoch 4/6 | train loss 0.0919 | val loss 0.3103 | val acc 0.8907 | val f1 0.8858\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2594 acc=0.8967 prec=0.9036 rec=0.8882 f1=0.8958\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4526  474]\n",
            " [ 559 4441]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.5303 | val loss 0.3989 | val acc 0.8314 | val f1 0.8297\n",
            "Epoch 2/6 | train loss 0.3512 | val loss 0.3460 | val acc 0.8576 | val f1 0.8697\n",
            "Epoch 3/6 | train loss 0.2773 | val loss 0.2857 | val acc 0.8820 | val f1 0.8878\n",
            "Epoch 4/6 | train loss 0.2157 | val loss 0.2644 | val acc 0.8961 | val f1 0.9003\n",
            "Epoch 5/6 | train loss 0.1658 | val loss 0.2691 | val acc 0.8971 | val f1 0.8947\n",
            "Epoch 6/6 | train loss 0.1204 | val loss 0.2904 | val acc 0.8960 | val f1 0.8943\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2726 acc=0.8905 prec=0.8656 rec=0.9246 f1=0.8941\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4282  718]\n",
            " [ 377 4623]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.4979 | val loss 0.3326 | val acc 0.8581 | val f1 0.8498\n",
            "Epoch 2/6 | train loss 0.2867 | val loss 0.2697 | val acc 0.8892 | val f1 0.8881\n",
            "Epoch 3/6 | train loss 0.1983 | val loss 0.2634 | val acc 0.8957 | val f1 0.8998\n",
            "Epoch 4/6 | train loss 0.1222 | val loss 0.2685 | val acc 0.8950 | val f1 0.8926\n",
            "Epoch 5/6 | train loss 0.0759 | val loss 0.3453 | val acc 0.8863 | val f1 0.8901\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2653 acc=0.8965 prec=0.8716 rec=0.9300 f1=0.8999\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4315  685]\n",
            " [ 350 4650]]\n"
          ]
        }
      ],
      "source": [
        "#BIGRU WITH W2V\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = BiGRU_W2V(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: BiGRU_W2V(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "FyYmfjPa09nf",
        "outputId": "15f7b99b-3d38-4cb2-d491-2d3e9e7127a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.270001    0.8949        0.872617   \n",
              "1         256  0.0010       6   0.259355    0.8967        0.903561   \n",
              "2         128  0.0005       6   0.272611    0.8905        0.865568   \n",
              "3         128  0.0010       6   0.265342    0.8965        0.871603   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.9248  0.897951           NaN  \n",
              "1       0.8882  0.895814           NaN  \n",
              "2       0.9246  0.894111           NaN  \n",
              "3       0.9300  0.899855       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0ea053c-4a0f-4b6f-8a56-4de8057546fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.270001</td>\n",
              "      <td>0.8949</td>\n",
              "      <td>0.872617</td>\n",
              "      <td>0.9248</td>\n",
              "      <td>0.897951</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.259355</td>\n",
              "      <td>0.8967</td>\n",
              "      <td>0.903561</td>\n",
              "      <td>0.8882</td>\n",
              "      <td>0.895814</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.272611</td>\n",
              "      <td>0.8905</td>\n",
              "      <td>0.865568</td>\n",
              "      <td>0.9246</td>\n",
              "      <td>0.894111</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.265342</td>\n",
              "      <td>0.8965</td>\n",
              "      <td>0.871603</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>0.899855</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0ea053c-4a0f-4b6f-8a56-4de8057546fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0ea053c-4a0f-4b6f-8a56-4de8057546fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0ea053c-4a0f-4b6f-8a56-4de8057546fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0058183810783040205,\n        \"min\": 0.2593554403543472,\n        \"max\": 0.2726110352277756,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2593554403543472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0028815508494813864,\n        \"min\": 0.890500009059906,\n        \"max\": 0.8967000246047974,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8967000246047974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017100996914013705,\n        \"min\": 0.8655682456468825,\n        \"max\": 0.9035605289928788,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9035605289928788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019295940851208386,\n        \"min\": 0.8881999999999999,\n        \"max\": 0.9299999999999998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8881999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025026676424394,\n        \"min\": 0.8941108210032718,\n        \"max\": 0.8998548621185134,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8958144225915321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZIIPjBlp_zL",
        "outputId": "20cd99b2-c934-4685-a5d3-0e16d0e68dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | train loss 0.4598 | val loss 0.2928 | val acc 0.8767 | val f1 0.8794\n",
            "Epoch 2/6 | train loss 0.2362 | val loss 0.2664 | val acc 0.8881 | val f1 0.8852\n",
            "Epoch 3/6 | train loss 0.1497 | val loss 0.2885 | val acc 0.8926 | val f1 0.8933\n",
            "Epoch 4/6 | train loss 0.0841 | val loss 0.3650 | val acc 0.8798 | val f1 0.8846\n",
            "Epoch 5/6 | train loss 0.0440 | val loss 0.4632 | val acc 0.8780 | val f1 0.8814\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2888 acc=0.8959 prec=0.8958 rec=0.8960 f1=0.8959\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4479  521]\n",
            " [ 520 4480]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.4339 | val loss 0.3549 | val acc 0.8469 | val f1 0.8622\n",
            "Epoch 2/6 | train loss 0.2314 | val loss 0.2623 | val acc 0.8930 | val f1 0.8923\n",
            "Epoch 3/6 | train loss 0.1474 | val loss 0.2938 | val acc 0.8866 | val f1 0.8893\n",
            "Epoch 4/6 | train loss 0.0823 | val loss 0.3342 | val acc 0.8842 | val f1 0.8826\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2639 acc=0.8961 prec=0.9061 rec=0.8838 f1=0.8948\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4542  458]\n",
            " [ 581 4419]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 256, 'lr': 0.001, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.4414 | val loss 0.2893 | val acc 0.8774 | val f1 0.8734\n",
            "Epoch 2/6 | train loss 0.2288 | val loss 0.2754 | val acc 0.8891 | val f1 0.8938\n",
            "Epoch 3/6 | train loss 0.1415 | val loss 0.2718 | val acc 0.8920 | val f1 0.8940\n",
            "Epoch 4/6 | train loss 0.0762 | val loss 0.3603 | val acc 0.8869 | val f1 0.8900\n",
            "Epoch 5/6 | train loss 0.0369 | val loss 0.4267 | val acc 0.8808 | val f1 0.8835\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2715 acc=0.8925 prec=0.8869 rec=0.8998 f1=0.8933\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4426  574]\n",
            " [ 501 4499]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.0005, 'epochs': 6}\n",
            "Epoch 1/6 | train loss 0.5151 | val loss 0.3462 | val acc 0.8511 | val f1 0.8565\n",
            "Epoch 2/6 | train loss 0.3024 | val loss 0.2967 | val acc 0.8748 | val f1 0.8690\n",
            "Epoch 3/6 | train loss 0.2249 | val loss 0.2739 | val acc 0.8909 | val f1 0.8900\n",
            "Epoch 4/6 | train loss 0.1737 | val loss 0.2991 | val acc 0.8879 | val f1 0.8870\n",
            "Epoch 5/6 | train loss 0.1278 | val loss 0.3516 | val acc 0.8806 | val f1 0.8857\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2794 acc=0.8863 prec=0.9032 rec=0.8654 f1=0.8839\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4536  464]\n",
            " [ 673 4327]]\n",
            "\n",
            "======================================================================\n",
            "CONFIG: {'hidden_dim': 128, 'lr': 0.001, 'epochs': 6, 'weight_decay': 1e-05}\n",
            "Epoch 1/6 | train loss 0.4504 | val loss 0.3116 | val acc 0.8673 | val f1 0.8582\n",
            "Epoch 2/6 | train loss 0.2343 | val loss 0.2625 | val acc 0.8909 | val f1 0.8917\n",
            "Epoch 3/6 | train loss 0.1471 | val loss 0.2890 | val acc 0.8850 | val f1 0.8875\n",
            "Epoch 4/6 | train loss 0.0837 | val loss 0.3379 | val acc 0.8826 | val f1 0.8843\n",
            "Early stopping (no val F1 improvement for 2 epochs).\n",
            "\n",
            "TEST:\n",
            "loss=0.2628 acc=0.8917 prec=0.8899 rec=0.8940 f1=0.8919\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            " [[4447  553]\n",
            " [ 530 4470]]\n"
          ]
        }
      ],
      "source": [
        "#BIGRU WITH GLOVE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df, batch_size=64)\n",
        "\n",
        "model = BiGRU_GloVe(hidden_dim=128)\n",
        "model, history = fit_model(model, train_loader, val_loader, device, epochs=6, lr=1e-3, patience=2)\n",
        "test_metrics = test_model(model, test_loader, device)\n",
        "\n",
        "\n",
        "def run_grid(make_model_fn, train_loader, val_loader, test_loader, device, grid):\n",
        "    results = []\n",
        "    for cfg in grid:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CONFIG:\", cfg)\n",
        "\n",
        "        model = make_model_fn(cfg)\n",
        "        model, _ = fit_model(\n",
        "            model, train_loader, val_loader, device,\n",
        "            epochs=cfg.get(\"epochs\", 6),\n",
        "            lr=cfg.get(\"lr\", 1e-3),\n",
        "            patience=cfg.get(\"patience\", 2),\n",
        "            grad_clip=cfg.get(\"grad_clip\", 1.0),\n",
        "            weight_decay=cfg.get(\"weight_decay\", 0.0),\n",
        "        )\n",
        "        test_m = test_model(model, test_loader, device)\n",
        "\n",
        "        results.append({\n",
        "            **cfg,\n",
        "            \"test_loss\": test_m[\"loss\"],\n",
        "            \"test_acc\": test_m[\"acc\"],\n",
        "            \"test_precision\": test_m[\"precision\"],\n",
        "            \"test_recall\": test_m[\"recall\"],\n",
        "            \"test_f1\": test_m[\"f1\"],\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "grid = [\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 256, \"lr\": 1e-3, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 5e-4, \"epochs\": 6},\n",
        "    {\"hidden_dim\": 128, \"lr\": 1e-3, \"epochs\": 6, \"weight_decay\": 1e-5},\n",
        "]\n",
        "results = run_grid(\n",
        "    make_model_fn=lambda cfg: BiGRU_GloVe(hidden_dim=cfg[\"hidden_dim\"]),\n",
        "    train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
        "    device=device, grid=grid\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "0Cqc2na51ed8",
        "outputId": "b3765551-a909-477b-f65e-1fd00602b8fc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hidden_dim      lr  epochs  test_loss  test_acc  test_precision  \\\n",
              "0         128  0.0010       6   0.263853    0.8961        0.906090   \n",
              "1         256  0.0010       6   0.271467    0.8925        0.886852   \n",
              "2         128  0.0005       6   0.279379    0.8863        0.903152   \n",
              "3         128  0.0010       6   0.262756    0.8917        0.889906   \n",
              "\n",
              "   test_recall   test_f1  weight_decay  \n",
              "0       0.8838  0.894806           NaN  \n",
              "1       0.8998  0.893279           NaN  \n",
              "2       0.8654  0.883873           NaN  \n",
              "3       0.8940  0.891949       0.00001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9715a26-e968-4281-a8f2-5c3926368445\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_dim</th>\n",
              "      <th>lr</th>\n",
              "      <th>epochs</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.263853</td>\n",
              "      <td>0.8961</td>\n",
              "      <td>0.906090</td>\n",
              "      <td>0.8838</td>\n",
              "      <td>0.894806</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.271467</td>\n",
              "      <td>0.8925</td>\n",
              "      <td>0.886852</td>\n",
              "      <td>0.8998</td>\n",
              "      <td>0.893279</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>6</td>\n",
              "      <td>0.279379</td>\n",
              "      <td>0.8863</td>\n",
              "      <td>0.903152</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.883873</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.262756</td>\n",
              "      <td>0.8917</td>\n",
              "      <td>0.889906</td>\n",
              "      <td>0.8940</td>\n",
              "      <td>0.891949</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9715a26-e968-4281-a8f2-5c3926368445')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9715a26-e968-4281-a8f2-5c3926368445 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9715a26-e968-4281-a8f2-5c3926368445');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"hidden_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          256,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00025,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0077191827945698056,\n        \"min\": 0.26275628068447116,\n        \"max\": 0.2793790752887726,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2714668807029724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004047614320050806,\n        \"min\": 0.8863000273704529,\n        \"max\": 0.8960999846458435,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8924999833106995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00953537160377036,\n        \"min\": 0.8868519613640842,\n        \"max\": 0.9060898093090013,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8868519613640842\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015092934329237187,\n        \"min\": 0.8653999999999998,\n        \"max\": 0.8997999999999998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8997999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004877604199880766,\n        \"min\": 0.883872944540405,\n        \"max\": 0.8948061152166711,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8932790628407586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1e-05,\n        \"max\": 1e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONCLUSION:"
      ],
      "metadata": {
        "id": "Tyq1M2jS7n3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF vectors represent token importance within documents but do not encode semantic similarity between words. Unlike GloVe and Word2Vec, which place similar words close in embedding space, TF-IDF treats words independently. As a result, recurrent models using TF-IDF-weighted embeddings struggled to capture deeper contextual meaning, leading to lower F1-scores."
      ],
      "metadata": {
        "id": "iZUelpMk7m81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Increasing the hidden dimension improved the model’s ability to capture patterns in the text by providing a larger representational capacity. Smaller hidden sizes sometimes led to underfitting, while larger sizes generally improved training performance. However, when the hidden size became too large, validation performance occasionally decreased due to overfitting."
      ],
      "metadata": {
        "id": "ui0H79597t0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning rate strongly influenced training stability. Higher learning rates allowed the model to converge faster but sometimes caused unstable validation performance. Lower learning rates led to more stable training and slightly better generalization, although convergence was slower"
      ],
      "metadata": {
        "id": "MVJNfk2t79Y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introducing dropout helped reduce overfitting by preventing the model from relying too heavily on specific hidden units. Without dropout, training performance was higher but validation performance sometimes decreased. Moderate dropout values (e.g., 0.2–0.3) generally improved generalization."
      ],
      "metadata": {
        "id": "H-9zkc-y8Blq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the number of epochs improved training performance initially, but after a certain point, validation performance stopped improving. This indicated overfitting, making early stopping important to prevent performance degradation on unseen data."
      ],
      "metadata": {
        "id": "paORaxOB8DUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight decay helped control model complexity by penalizing large weights. Small values improved generalization slightly, while larger values caused underfitting by restricting the model too much."
      ],
      "metadata": {
        "id": "asAIImQg8FEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smaller batch sizes introduced more variability in gradient updates, which sometimes improved generalization. Larger batch sizes produced more stable training but did not always lead to better validation performance."
      ],
      "metadata": {
        "id": "b1B7bOBp8Fdq"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}